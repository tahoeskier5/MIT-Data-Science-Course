{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tahoeskier5/MIT-Data-Science-Course/blob/main/SoftImpute_for_Movielens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3c46e94",
      "metadata": {
        "id": "b3c46e94"
      },
      "source": [
        "#  The MovieLens Dataset\n",
        "\n",
        "[MovieLens](https://movielens.org/) is a non-commercial web-based movie recommender system, created in 1997 by GroupLens, a research lab at the University of Minnesota, in order to gather movie rating data for research purposes.\n",
        "\n",
        "\n",
        "## Getting the Data\n",
        "\n",
        "\n",
        "The MovieLens dataset is hosted by the [GroupLens](https://grouplens.org/datasets/movielens/) website. Several versions are available. We will use the latest smallest dataset released from [link](https://files.grouplens.org/datasets/movielens/ml-latest-small.zip).\n",
        "\n",
        "## Custom Code\n",
        "\n",
        "The custom packages; soft_impute and functionsCF will need to be installed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the standard papackages\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install fancyimpute"
      ],
      "metadata": {
        "id": "f5x_KMp8fpxo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "517a4a8a-d147-47f7-f068-03b8deb0d2a6"
      },
      "id": "f5x_KMp8fpxo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fancyimpute in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: knnimpute>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from fancyimpute) (0.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from fancyimpute) (1.0.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from fancyimpute) (3.6.4)\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.7/dist-packages (from fancyimpute) (1.3.0)\n",
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.7/dist-packages (from fancyimpute) (1.2.1)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (from fancyimpute) (1.3.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.7/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (3.1.0)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.7/dist-packages (from cvxpy->fancyimpute) (2.0.10)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from cvxpy->fancyimpute) (0.6.2.post0)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from cvxpy->fancyimpute) (3.2.0)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.7/dist-packages (from osqp>=0.4.1->cvxpy->fancyimpute) (0.1.5.post2)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (8.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (57.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (1.11.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (22.1.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Collab Connection to Google Drive: External data: Local Files, Drive, Sheets, and Cloud Storage\n",
        "https://colab.research.google.com/notebooks/io.ipynb"
      ],
      "metadata": {
        "id": "cA4Pv9fGpe19"
      },
      "id": "cA4Pv9fGpe19"
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "AFNnBYR2hAEB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90c86d98-3f14-4c2b-973d-d732fe6393a0"
      },
      "id": "AFNnBYR2hAEB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# location of custom packages: soft_impute , functionsCF, and dataset ratings.csv\n",
        "# CollaborativeFiltering folder in google drive\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/CollaborativeFiltering/')"
      ],
      "metadata": {
        "id": "IsIo2LkxhhQl"
      },
      "id": "IsIo2LkxhhQl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change the working directory\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/CollaborativeFiltering/\")"
      ],
      "metadata": {
        "id": "qv7OvJ8nr0TU"
      },
      "id": "qv7OvJ8nr0TU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8ae0c8f",
      "metadata": {
        "id": "e8ae0c8f"
      },
      "outputs": [],
      "source": [
        "# Impute necessary packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from fancyimpute import BiScaler\n",
        "from soft_impute import SoftImpute\n",
        "from functionsCF import GenerateTrainingSet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40bbbdd4",
      "metadata": {
        "id": "40bbbdd4"
      },
      "source": [
        "## Create the incomplete matrices for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read movielens data from files- point to where data is stored, small set of Movielens dataset\n",
        "# 100836 (rows), userId\tmovieId\trating\ttimestamp (columns).\n",
        "# Using smaller dataset rather than the full dataset to speed performance.\n",
        "# Your results may vary depending on which Movielens data set is used; Several are available online\n",
        "# read in values only\n",
        "rating = pd.read_csv('ratings.csv', sep=',').values"
      ],
      "metadata": {
        "id": "Vsbz4zO0j7DB"
      },
      "id": "Vsbz4zO0j7DB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we only care about the ratings, so we only use the first three columns, which contain use IDs, movie IDs, and ratings.\n",
        "rating = rating[:,0:3]"
      ],
      "metadata": {
        "id": "ptTHCfTfxBuC"
      },
      "id": "ptTHCfTfxBuC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show top 5 rows\n",
        "print(rating[:5, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-i471csu_K3",
        "outputId": "8354b583-ed27-4ef5-dac5-24de4297d3d0"
      },
      "id": "a-i471csu_K3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.  1.  4.]\n",
            " [ 1.  3.  4.]\n",
            " [ 1.  6.  4.]\n",
            " [ 1. 47.  5.]\n",
            " [ 1. 50.  5.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b23d947b",
      "metadata": {
        "id": "b23d947b"
      },
      "outputs": [],
      "source": [
        "# Use all known information to create the incomplete matrix\n",
        "\n",
        "# First, create an empty matrix\n",
        "matrix_incomplete = np.zeros((len(np.unique(rating[:,0])), len(np.unique(rating[:,1]))))\n",
        "\n",
        "# Second, Since some movies don't have any ratings, we only use the movies that have ratings.\n",
        "# Here we correspondingly change the movie IDs to make each column has ratings.\n",
        "# create an array of all movie IDs\n",
        "usedID = np.unique(rating[:, 1])\n",
        "# replace the movie IDs by the their positions in the array we just created\n",
        "for i in range(len(rating[:,1])):\n",
        "    rating[:,1][i] = np.where(usedID==rating[:,1][i])[0][0] + 1\n",
        "\n",
        "# Finally, we construct the incomplete matrix, on which the incomplete components are nan by\n",
        "# default.\n",
        "# all components are nan by default\n",
        "matrix_incomplete[:] = np.nan\n",
        "# create the index pair of the components with ratings\n",
        "indices = np.array(rating[:,0] - 1).astype(int), np.array(rating[:,1] - 1).astype(int)\n",
        "# change the values in the corresponding positions to the known rating information\n",
        "matrix_incomplete[indices] = rating[:,2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f54b0e6",
      "metadata": {
        "id": "2f54b0e6"
      },
      "outputs": [],
      "source": [
        "# Obtain the index pairs of the training set and the validation set, with ratio 90%\n",
        "train_indices, validation_indices = GenerateTrainingSet(rating[:,0], rating[:,1], 0.90)\n",
        "# And then use the index pairs to create the incomplete training test\n",
        "matrix_train = matrix_incomplete.copy()\n",
        "matrix_train[:] = np.nan\n",
        "matrix_train[train_indices] = matrix_incomplete[train_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69a998c9",
      "metadata": {
        "id": "69a998c9"
      },
      "source": [
        "##  Run the softImpute model for collaborative filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d16d1db",
      "metadata": {
        "id": "0d16d1db"
      },
      "outputs": [],
      "source": [
        "# Create the BiScaler model\n",
        "biscaler = BiScaler(scale_rows=False, scale_columns=False, max_iters=50, verbose=False)\n",
        "# Rescale both rows and columns to have zero mean\n",
        "matrix_train_normalized = biscaler.fit_transform(matrix_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae5de031",
      "metadata": {
        "id": "ae5de031"
      },
      "outputs": [],
      "source": [
        "# Use softImpute to complete the matrix. J means the number of archetypes and rand_seed means the\n",
        "# seed for the inner random number generator, verbose control whether outputting algorithm logs.\n",
        "softImpute = SoftImpute(J = 4, maxit = 200, random_seed = 1, verbose = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19484161",
      "metadata": {
        "id": "19484161"
      },
      "outputs": [],
      "source": [
        "# Run the softImpute model on the normalized training set\n",
        "matrix_train_softImpute = softImpute.fit(matrix_train_normalized)\n",
        "# Use the softImpute model to create the predicted matrix. If we set copyto as True, then it\n",
        "# directly change the value of matrix_train_normalized\n",
        "matrix_train_filled_normalized = matrix_train_softImpute.predict(matrix_train_normalized, copyto = False)\n",
        "# Inverse transformation to undo the scaling\n",
        "matrix_train_filled = biscaler.inverse_transform(matrix_train_filled_normalized)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9481eb67",
      "metadata": {
        "id": "9481eb67"
      },
      "source": [
        "## Analysis of the predicted ratings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "988d616f",
      "metadata": {
        "id": "988d616f"
      },
      "source": [
        "### Out-of-sample R^2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a097cfe2",
      "metadata": {
        "id": "a097cfe2"
      },
      "outputs": [],
      "source": [
        "# Create the baseline method\n",
        "train_average = np.average(matrix_train[train_indices])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d89639dd",
      "metadata": {
        "id": "d89639dd",
        "outputId": "b4aef0cf-8ff5-4e89-c5a7-8de28c90520f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out-of-sample R2: 0.1934, in-sample R2: 0.6391.\n"
          ]
        }
      ],
      "source": [
        "# Calculate out-of-sample R2 and in-sample R2\n",
        "# Your results may vary from the lesson due to datasize and training test split.\n",
        "validation_mse = ((matrix_train_filled[validation_indices] - matrix_incomplete[validation_indices]) ** 2).mean()\n",
        "training_mse = ((matrix_train_filled[train_indices] - matrix_incomplete[train_indices]) ** 2).mean()\n",
        "validation_mse_baseline = ((train_average - matrix_incomplete[validation_indices]) ** 2).mean()\n",
        "training_mse_baseline = ((train_average - matrix_incomplete[train_indices]) ** 2).mean()\n",
        "print(\"out-of-sample R2: %.4f, in-sample R2: %.4f.\" % (1 - validation_mse / validation_mse_baseline, 1 - training_mse / training_mse_baseline))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d09890c5",
      "metadata": {
        "id": "d09890c5"
      },
      "source": [
        "### Get low-rank factors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78125afd",
      "metadata": {
        "id": "78125afd",
        "outputId": "5ca006ad-237a-4cac-918a-8efde9fe19db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00575397, -0.01470188,  0.00090158, -0.0025786 ],\n",
              "       [-0.00385644, -0.00907926, -0.0010775 , -0.0036327 ],\n",
              "       [ 0.00137671, -0.0102478 , -0.00104006, -0.00884355],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# Obtain the ratings of each archetype\n",
        "# Each row of this matrix corresponds to a song and each column corresponds to an archetype\n",
        "softImpute.v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c37024e",
      "metadata": {
        "id": "1c37024e",
        "outputId": "0e4e1c3f-d785-4171-f3b4-403aae3fbc1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9724, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "softImpute.v.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6250e638",
      "metadata": {
        "id": "6250e638",
        "outputId": "2f39c99f-48e2-4a87-83ca-0796449fdde6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ -0.85494694, -13.44541157,  -1.87133902,  10.44381138],\n",
              "       [-11.18041355,  -7.16252836,  17.03209691,  12.97563129],\n",
              "       [-67.34569219,  21.39173972,  23.43862095, -29.37540049],\n",
              "       ...,\n",
              "       [-28.38972891,  40.53371271, -15.24055298,   6.16517951],\n",
              "       [ -7.41266477,  -0.7577943 ,   0.90454472,   9.5119234 ],\n",
              "       [ 20.15436593,   3.42299304,  14.38067962,  10.33522778]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# (Optional)\n",
        "# Obtain the weights of archetypes of each user\n",
        "# each row of this matrix corresponds to a user and each column corresponds to an archetype\n",
        "weights = np.dot(softImpute.u, np.diagflat(softImpute.d).T)\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3dd121c",
      "metadata": {
        "id": "c3dd121c",
        "outputId": "e9ad2066-ab99-47b4-ee62-aca30747dd4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(610, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "weights.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf2f7437",
      "metadata": {
        "id": "cf2f7437"
      },
      "outputs": [],
      "source": [
        "# And then the predicted matrix is computed by the product of two low-rank matrices\n",
        "new_prediction = np.dot(weights, softImpute.v.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7421f9c",
      "metadata": {
        "id": "d7421f9c",
        "outputId": "7a56ee67-1a55-4a39-9b02-e04edad2cd37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.826225376082049e-11"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "# We can see it is the same with the output of the codes in the previous section\n",
        "np.sum(np.abs(new_prediction - matrix_train_filled_normalized))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0831b6a",
      "metadata": {
        "id": "c0831b6a"
      },
      "source": [
        "end of the note"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}